{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBs50UOwApXj",
        "outputId": "48ada3a9-1702-40d4-bfeb-f36142b56f02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/dist-packages (2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (0.11.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlL4SSLJVIqF",
        "outputId": "4256d3a8-0353-43f3-c790-07fda1d89be7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import Accuracy, F1Score, Precision, Recall, MetricCollection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import zipfile\n",
        "import io\n",
        "from PIL import Image\n",
        "import struct\n",
        "import os\n",
        "import csv\n",
        "from tensorboardX import SummaryWriter\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "45FW8Seb97EG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive = zipfile.ZipFile('/content/drive/MyDrive/train_set.zip', 'r')\n",
        "archive2 = zipfile.ZipFile('/content/drive/MyDrive/test_set.zip', 'r')\n",
        "archive3 = zipfile.ZipFile('/content/drive/MyDrive/negatives.zip', 'r')\n",
        "archive4 = zipfile.ZipFile('/content/drive/MyDrive/test_set4.zip', 'r')\n",
        "archive5 = zipfile.ZipFile('/content/drive/MyDrive/test_set5.zip', 'r')\n",
        "archive6 = zipfile.ZipFile('/content/drive/MyDrive/test_set6.zip', 'r')\n",
        "archive7 = zipfile.ZipFile('/content/drive/MyDrive/test_set7.zip', 'r')\n",
        "archive8 = zipfile.ZipFile('/content/drive/MyDrive/test_set8.zip', 'r')\n",
        "archive9 = zipfile.ZipFile('/content/drive/MyDrive/test_set9.zip', 'r')\n",
        "archive10 = zipfile.ZipFile('/content/drive/MyDrive/test_set10.zip', 'r')\n",
        "archive11 = zipfile.ZipFile('/content/drive/MyDrive/test_set11.zip', 'r')\n",
        "archive12 = zipfile.ZipFile('/content/drive/MyDrive/test_set12.zip', 'r')\n",
        "archive13 = zipfile.ZipFile('/content/drive/MyDrive/test_set13.zip', 'r')\n",
        "archive14 = zipfile.ZipFile('/content/drive/MyDrive/test_set14.zip', 'r')\n",
        "archive15 = zipfile.ZipFile('/content/drive/MyDrive/test_set15.zip', 'r')"
      ],
      "metadata": {
        "id": "r4JuNTTgN3LH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive.extractall()\n",
        "archive2.extractall()\n",
        "archive3.extractall()\n",
        "archive4.extractall()\n",
        "archive5.extractall()\n",
        "archive6.extractall()\n",
        "archive7.extractall()\n",
        "archive8.extractall()\n",
        "archive9.extractall()\n",
        "archive10.extractall()\n",
        "archive11.extractall()\n",
        "archive12.extractall()\n",
        "archive13.extractall()\n",
        "archive14.extractall()\n",
        "archive15.extractall()"
      ],
      "metadata": {
        "id": "2s-RCHZBlDjb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletDataloader1(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pos_data_path, neg_data_path, phase, sizes):\n",
        "        self.pos_list = pos_data_path\n",
        "        self.dirs_neg = os.listdir(neg_data_path)\n",
        "        self.phase = phase\n",
        "        self.sizes = sizes\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        self.offset_index = 0\n",
        "        self.img_no = 2\n",
        "        for i in range(len(self.sizes)):\n",
        "          if index >= self.sizes[i]:\n",
        "            self.offset_index = self.sizes[i]\n",
        "            self.img_no += 1\n",
        "        if self.phase == 'train':\n",
        "          rand_no = random.randint(1, self.img_no-1)\n",
        "          try:\n",
        "            if self.img_no < 10:\n",
        "              imgFile1 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + f'_000{self.img_no}.jpg'\n",
        "            else:\n",
        "              imgFile1 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + f'_00{self.img_no}.jpg'\n",
        "            if rand_no < 10:\n",
        "              imgFile2 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + f'_000{rand_no}.jpg'\n",
        "            else:\n",
        "              imgFile2 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index] + f'_00{rand_no}.jpg'\n",
        "            img1, label1 = np.array(Image.open(imgFile1), dtype=float), os.listdir(self.pos_list[self.img_no-2])[index - self.offset_index]\n",
        "            img2 = np.array(Image.open(imgFile2), dtype=float)\n",
        "          except:\n",
        "            if self.img_no < 10:\n",
        "              imgFile1 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + f'_000{self.img_no}.jpg'\n",
        "            else:\n",
        "              imgFile1 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + f'_00{self.img_no}.jpg'\n",
        "            if rand_no < 10:\n",
        "              imgFile2 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + f'_000{rand_no}.jpg'\n",
        "            else:\n",
        "              imgFile2 = self.pos_list[self.img_no-2] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + '/' + os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index] + f'_00{rand_no}.jpg'\n",
        "            img1, label1 = np.array(Image.open(imgFile1), dtype=float), os.listdir(self.pos_list[self.img_no-2])[index + 1 - self.offset_index]\n",
        "            img2 = np.array(Image.open(imgFile2), dtype=float)\n",
        "        else:\n",
        "          rand_no = random.randint(1, len(self.sizes))\n",
        "          try:\n",
        "            imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index] + '/' + os.listdir(self.pos_list)[index] + '_0015.jpg'\n",
        "            imgFile2 = self.pos_list + '/' + os.listdir(self.pos_list)[index] + '/' + os.listdir(self.pos_list)[index] + f'_000{rand_no}.jpg'\n",
        "            img1, label1 = np.array(Image.open(imgFile1), dtype=float), os.listdir(self.pos_list)[index]\n",
        "            img2 = np.array(Image.open(imgFile2), dtype=float)\n",
        "          except:\n",
        "            imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index+1] + '/' + os.listdir(self.pos_list)[index+1] + '_0015.jpg'\n",
        "            imgFile2 = self.pos_list + '/' + os.listdir(self.pos_list)[index+1] + '/' + os.listdir(self.pos_list)[index+1] + f'_000{rand_no}.jpg'\n",
        "            img1, label1 = np.array(Image.open(imgFile1), dtype=float), os.listdir(self.pos_list)[index+1]\n",
        "            img2 = np.array(Image.open(imgFile2), dtype=float)\n",
        "\n",
        "        rand_index = np.random.choice(len(self.dirs_neg))\n",
        "        imgFile3 = 'negatives/' + self.dirs_neg[rand_index] + '/' + self.dirs_neg[rand_index] + '_0001.jpg'\n",
        "        img3, label3 = np.array(Image.open(imgFile3), dtype=float), self.dirs_neg[rand_index]\n",
        "\n",
        "        img1 = np.transpose(img1, (2, 0, 1))\n",
        "        img2 = np.transpose(img2, (2, 0, 1))\n",
        "        img3 = np.transpose(img3, (2, 0, 1))\n",
        "\n",
        "        return (img1, img2, img3), (label1, label3)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sizes[-1]"
      ],
      "metadata": {
        "id": "bJTb4SNRJFEG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletDataloader(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pos_data_path, neg_data_path, phase):\n",
        "        self.pos_list = pos_data_path\n",
        "        self.dirs_neg = os.listdir(neg_data_path)\n",
        "        self.phase = phase\n",
        "        self.sizes = sizes\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        train_pos_list = []\n",
        "        train_neg_list = []\n",
        "        if self.phase == 'train':\n",
        "          for idx in range(len(os.listdir(self.pos_list + '/' + os.listdir(self.pos_list)[index]))):\n",
        "            try:\n",
        "              if idx < 9:\n",
        "                imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index] + '/' + os.listdir(self.pos_list)[index] + f'_000{idx + 1}.jpg'\n",
        "              elif idx < 99:\n",
        "                imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index] + '/' + os.listdir(self.pos_list)[index] + f'_00{idx + 1}.jpg'\n",
        "              img1 = np.array(Image.open(imgFile1), dtype=float)\n",
        "            except:\n",
        "              if idx < 10:\n",
        "                imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index+1] + '/' + os.listdir(self.pos_list)[index+1] + f'_000{idx + 1}.jpg'\n",
        "              elif idx < 99:\n",
        "                imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index+1] + '/' + os.listdir(self.pos_list)[index+1] + f'_00{idx + 1}.jpg'\n",
        "              img1 = np.array(Image.open(imgFile1), dtype=float)\n",
        "            if idx != 15:\n",
        "              img1 = np.transpose(img1, (2, 0, 1))\n",
        "              train_pos_list.append(img1)\n",
        "            \n",
        "              rand_index = np.random.choice(len(self.dirs_neg))\n",
        "              imgFile3 = 'negatives/' + self.dirs_neg[rand_index] + '/' + self.dirs_neg[rand_index] + '_0001.jpg'\n",
        "              img3 = np.array(Image.open(imgFile3), dtype=float)\n",
        "              img3 = np.transpose(img3, (2, 0, 1))\n",
        "              train_neg_list.append(img3)\n",
        "\n",
        "          label1 = os.listdir(self.pos_list)[index]\n",
        "\n",
        "        else:\n",
        "          rand_no = random.randint(1, 9)\n",
        "          try:\n",
        "            imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index] + '/' + os.listdir(self.pos_list)[index] + '_0015.jpg'\n",
        "            imgFile2 = self.pos_list + '/' + os.listdir(self.pos_list)[index] + '/' + os.listdir(self.pos_list)[index] + f'_000{rand_no}.jpg'\n",
        "            img1, label1 = np.array(Image.open(imgFile1), dtype=float), os.listdir(self.pos_list)[index]\n",
        "            img2 = np.array(Image.open(imgFile2), dtype=float)\n",
        "          except:\n",
        "            imgFile1 = self.pos_list + '/' + os.listdir(self.pos_list)[index+1] + '/' + os.listdir(self.pos_list)[index+1] + '_0015.jpg'\n",
        "            imgFile2 = self.pos_list + '/' + os.listdir(self.pos_list)[index+1] + '/' + os.listdir(self.pos_list)[index+1] + f'_000{rand_no}.jpg'\n",
        "            img1, label1 = np.array(Image.open(imgFile1), dtype=float), os.listdir(self.pos_list)[index+1]\n",
        "            img2 = np.array(Image.open(imgFile2), dtype=float)\n",
        "          \n",
        "          img1 = np.transpose(img1, (2, 0, 1))\n",
        "          img2 = np.transpose(img2, (2, 0, 1))\n",
        "          train_pos_list.append(img1)\n",
        "          train_pos_list.append(img2)\n",
        "\n",
        "          rand_index = np.random.choice(len(self.dirs_neg))\n",
        "          imgFile3 = 'negatives/' + self.dirs_neg[rand_index] + '/' + self.dirs_neg[rand_index] + '_0001.jpg'\n",
        "          img3 = np.array(Image.open(imgFile3), dtype=float)\n",
        "          img3 = np.transpose(img3, (2, 0, 1))\n",
        "          train_neg_list.append(img3)\n",
        "\n",
        "        return (np.array(train_pos_list), np.array(train_neg_list)), (label1)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.pos_list))"
      ],
      "metadata": {
        "id": "H7jUCFhIkV_J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLoss(nn.Module):  # x=TripletLos(); x(input) -> \n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        euc_distance_positive = (anchor - positive).pow(2).sum(1)\n",
        "        euc_distance_negative = (anchor - negative).pow(2).sum(1)\n",
        "        losses = F.relu(euc_distance_positive - euc_distance_negative + self.margin)   #relu(x)= x if x>0 else 0\n",
        "        return losses.mean()"
      ],
      "metadata": {
        "id": "jB11-TpO93qk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3C21f1dW9K84"
      },
      "outputs": [],
      "source": [
        "class DeepArchitecture(nn.Module):\n",
        "    def __init__(self, embed_size):\n",
        "        super(DeepArchitecture, self).__init__()\n",
        "        self.convnet = nn.Sequential(nn.Conv2d(3, 32, 5), nn.ReLU(),  # in_channels, out_channels, kernel_size,  kernel size, stride, num kernels\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     nn.Conv2d(32, 64, 5), nn.ReLU(),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     nn.Conv2d(64, 128, 5), nn.ReLU(),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     nn.Conv2d(128, 256, 5), nn.ReLU(),\n",
        "                                     nn.MaxPool2d(2))\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(256*121, 2*embed_size),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(2*embed_size, 2*embed_size),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(2*embed_size, embed_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.convnet(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class FaceNet(nn.Module):\n",
        "    def __init__(self, embed_size, is_train):\n",
        "        super(FaceNet, self).__init__()\n",
        "        self.deep_arch = DeepArchitecture(embed_size=embed_size)\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def l2_norm(self, input):\n",
        "        input_size = input.size()\n",
        "        buffer = torch.pow(input, 2)\n",
        "        normp = torch.sum(buffer, 1).add_(1e-10)\n",
        "        norm = torch.sqrt(normp)\n",
        "        _output = torch.div(input, norm.view(-1, 1).expand_as(input))\n",
        "        output = _output.view(input_size)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        if self.is_train:\n",
        "          output1 = self.deep_arch(x1)\n",
        "          output2 = self.deep_arch(x2)\n",
        "          output3 = self.deep_arch(x3)\n",
        "          output1 = self.l2_norm(output1)\n",
        "          output2 = self.l2_norm(output2)\n",
        "          output3 = self.l2_norm(output3)\n",
        "          return output1, output2, output3\n",
        "        else:\n",
        "          output1 = self.deep_arch(x1)\n",
        "          output1 = self.l2_norm(output1)\n",
        "          return output1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(train_dataset, val_dataset, dataloader_workers: int = 2, batch_size: int = 8):\n",
        "    \n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        **kwargs\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        drop_last=False,\n",
        "        shuffle=False,\n",
        "        **kwargs\n",
        "    )\n",
        "    return {'train': train_loader, 'val': val_loader}\n",
        "\n",
        "def get_test_dataloaders(test_dataset, dataloader_workers: int = 2, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "    @param test_dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        **kwargs\n",
        "    )\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "is0lQHtJ_00W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(anchor, positive, negative, loss_fn):\n",
        "    loss = loss_fn(anchor, positive, negative)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "nZljxWjQAB1O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(total_loss):\n",
        "    plt.plot(total_loss[\"train\"], color='blue')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.plot(total_loss[\"val\"], color='red')\n",
        "    plt.legend(['train_loss', 'val_loss'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VGCt19tkAGcL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, loss_func, optimizer_func, use_cuda, epochs, checkpoint_path_model = \"/content/chckpnt3.pth\", trained_epochs: int = 0, tb_writer = None):\n",
        "    best_loss = 1e10\n",
        "    total_acc = {key: [] for key in ['train', 'val']}\n",
        "    total_loss = {key: [] for key in ['train', 'val']}\n",
        "    loss_fn = loss_func\n",
        "    optimizer = optimizer_func\n",
        "    since = time.time()\n",
        "\n",
        "    metrics = MetricCollection([])\n",
        "\n",
        "    train_metrics = metrics.clone(prefix=\"train\")\n",
        "    val_metrics = metrics.clone(prefix=\"val\")\n",
        "\n",
        "    # iterate over all epochs\n",
        "    for epoch in range(trained_epochs, epochs):\n",
        "        print(f'Epoch {epoch+1}/{epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0\n",
        "            for dic in tqdm(dataloaders[phase], total=len(dataloaders[phase])):\n",
        "                inputs, labels = dic\n",
        "\n",
        "                if use_cuda:\n",
        "                    inputs = list(inps.to('cuda', dtype=torch.float) for inps in inputs) # [batch_size, in_channels, H, W]\n",
        "                    #labels = (lbls.cuda() for lbls in labels)\n",
        "\n",
        "                optimizer.zero_grad()  # zero the parameter gradients\n",
        "\n",
        "                # forward pass: compute prediction and the loss btw prediction and true label\n",
        "                # track history only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #loss_list = []\n",
        "                    if phase == 'val':\n",
        "                      print(len(inputs), inputs[1][0])\n",
        "                    for i in range(inputs[0].shape[1] - 1):\n",
        "                      rand_no_list = random.sample(range(0, inputs[0].shape[1]), 2)\n",
        "                      pos_inp1 = inputs[0][0, rand_no_list[0]]\n",
        "                      pos_inp2 = inputs[0][0, rand_no_list[1]]\n",
        "                      neg_input = inputs[1][0, rand_no_list[0]]\n",
        "                    \n",
        "                      outputs = model(torch.unsqueeze(pos_inp1, axis=0), torch.unsqueeze(pos_inp2, axis=0), torch.unsqueeze(neg_input, axis=0))\n",
        "                    \n",
        "                      # output is binary [batch size, n_classes, H, W], target is class [batch size, 1, H, W]\n",
        "                      loss = calc_loss(*outputs, loss_fn)\n",
        "\n",
        "                    # backward + optimize only if in training phase (no need for torch.no_grad in this training pass)\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss # * outputs[0].shape[0]\n",
        "\n",
        "            if phase == \"train\":\n",
        "                computed_metrics = train_metrics.compute()\n",
        "                train_metrics.reset()\n",
        "            elif phase == \"val\":\n",
        "                computed_metrics = val_metrics.compute()\n",
        "                val_metrics.reset()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            computed_metrics[f\"{phase}Loss\"] = epoch_loss\n",
        "\n",
        "            epoch_summary = f'Epoch {phase} : {epoch+1}'\n",
        "            for k, v in computed_metrics.items():\n",
        "              epoch_summary = f\"{epoch_summary}\\n\\t{k} : {v:.6f}\"\n",
        "\n",
        "            print(epoch_summary)\n",
        "\n",
        "            total_loss[phase].append(computed_metrics[f\"{phase}Loss\"].item())\n",
        "\n",
        "        \n",
        "            # Display metrics in Tensorboard\n",
        "            if tb_writer is not None:\n",
        "                for item in [\"Loss\"]:\n",
        "                    tb_writer.add_scalar(f\"{item}/{phase}\", computed_metrics[f\"{phase}{item}\"], epoch)\n",
        "\n",
        "            # save the model weights in validation phase \n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                    print(f\"saving best model to {checkpoint_path_model}\")\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), checkpoint_path_model)\n",
        "\n",
        "        # Display total time\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Total time elapsed: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    plot_training(total_loss)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path_model))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lWdM_0l9AXYO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "resume = False\n",
        "sizes = []\n",
        "# train_set_list = ['/content/test_set5', '/content/test_set6', '/content/test_set7', '/content/test_set8',\n",
        "#                   '/content/test_set9', '/content/test_set10', '/content/test_set11', '/content/test_set12', '/content/test_set13', '/content/test_set14'] # '/content/train_set', '/content/test_set', '/content/test_set4', \n",
        "# initial = 0\n",
        "# for i in range(len(train_set_list)):\n",
        "#   sizes.append(len(os.listdir(train_set_list[i]))+ initial)\n",
        "#   initial = sizes[i]\n",
        "triplet_train_dataset = TripletDataloader('/content/test_set9', '/content/negatives', 'train')\n",
        "triplet_test_dataset = TripletDataloader('/content/test_set15', '/content/negatives', 'val') #, [len(os.listdir('/content/test_set15'))])\n",
        "batch_size = 1\n",
        "dataloaders = get_dataloaders(triplet_train_dataset, triplet_test_dataset, batch_size=batch_size)\n",
        "test_set = get_test_dataloaders(triplet_test_dataset, batch_size=batch_size)\n",
        "\n",
        "margin = 0.2\n",
        "model = FaceNet(embed_size=128, is_train=True)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "if resume:\n",
        "  model.load_state_dict(torch.load(\"/content/chckpnt.pth\"))\n",
        "loss_fn = TripletLoss(margin)\n",
        "lr = 1e-3\n",
        "wd = 1e-5\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=lr, weight_decay=wd)\n",
        "n_epochs = 100\n",
        "writer = SummaryWriter(\"/content/drive/MyDrive/runs/9\")"
      ],
      "metadata": {
        "id": "gP5_buswBMlJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, dataloaders, loss_fn, optimizer, torch.cuda.is_available(), n_epochs, checkpoint_path_model=\"/content/drive/MyDrive/chckpnt9_embed128_allData_model.pth\", tb_writer = writer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sKJ_89-bVhU",
        "outputId": "eeab8d93-f485-45cb-ca90-5e60443129f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–Œ         | 9/176 [00:07<01:47,  1.55it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/runs\""
      ],
      "metadata": {
        "id": "s2n5EPhc8-72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FaceNet(embed_size=128, is_train=False)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "J5QEBksci96p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/chckpnt8_embed128_lessData_model.pth\"))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "      embed_list = []\n",
        "      file_path = '/content/test_set5'\n",
        "      for index in range(len(os.listdir(file_path))):\n",
        "        \n",
        "        label1 = os.listdir(file_path)[index]\n",
        "        for i in range(len(os.listdir(file_path + '/' + os.listdir(file_path)[index]))):\n",
        "          if i < 9:\n",
        "            imgFile1 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + f'_000{i+1}.jpg'\n",
        "          # elif i < 14:\n",
        "          #   imgFile1 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + f'_00{i+1}.jpg'\n",
        "          elif i < 99:\n",
        "            imgFile1 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + f'_00{i+1}.jpg'\n",
        "          else:\n",
        "            # try:\n",
        "            imgFile1 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + f'_0{i+1}.jpg'\n",
        "            # except:\n",
        "            # pass\n",
        "          img1 = np.array(Image.open(imgFile1), dtype='float32')\n",
        "\n",
        "          img1 = np.transpose(img1, (2, 0, 1))\n",
        "\n",
        "        \n",
        "          inputs = (img1, img1, img1)\n",
        "          if torch.cuda.is_available():\n",
        "            inputs = list(torch.tensor(inps).to('cuda', dtype=torch.float32) for inps in inputs)\n",
        "          embed1 = model(torch.unsqueeze(inputs[0], axis=0), torch.unsqueeze(inputs[1], axis=0), torch.unsqueeze(inputs[2], axis=0))\n",
        "\n",
        "          embed_list.append([label1, embed1, imgFile1])\n",
        "\n",
        "\n",
        "      # for index in range(len(os.listdir('/content/negatives'))):\n",
        "      #   neg_file = '/content/negatives'\n",
        "\n",
        "      #   imgFile1 = 'negatives/' + os.listdir(neg_file)[index] + '/' + os.listdir(neg_file)[index] + '_0001.jpg'\n",
        "      #   img1, label1 = np.array(Image.open(imgFile1), dtype='float32'), os.listdir(neg_file)[index]\n",
        "\n",
        "      #   img1 = np.transpose(img1, (2, 0, 1))\n",
        "\n",
        "        \n",
        "      #   inputs = (img1, img1, img1)\n",
        "      #   if torch.cuda.is_available():\n",
        "      #     inputs = list(torch.tensor(inps).to('cuda', dtype=torch.float32) for inps in inputs)\n",
        "      #   embed1 = model(torch.unsqueeze(inputs[0], axis=0), torch.unsqueeze(inputs[1], axis=0), torch.unsqueeze(inputs[2], axis=0))\n",
        "      #   # data rows as dictionary objects\n",
        "      #   embed_list.append([label1, embed1, imgFile1])"
      ],
      "metadata": {
        "id": "oWwfacXGGJG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, use_cuda, embed_list, file_path = '/content/test_set15'):\n",
        "  \n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "        acc = 0\n",
        "        for index in range(len(os.listdir(file_path))):\n",
        "\n",
        "          euc_dist = 0\n",
        "          imgFile1 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + '_0015.jpg'\n",
        "\n",
        "          imgFile2 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + '_0002.jpg'\n",
        "          img1, label1 = np.array(Image.open(imgFile1), dtype='float32'), os.listdir(file_path)[index]\n",
        "          img2 = np.array(Image.open(imgFile2), dtype='float32')\n",
        "\n",
        "\n",
        "          img1 = np.transpose(img1, (2, 0, 1))\n",
        "          img2 = np.transpose(img2, (2, 0, 1))\n",
        "\n",
        "          \n",
        "          inputs = (img1, img2, img2)\n",
        "          if torch.cuda.is_available():\n",
        "            inputs = list(torch.tensor(inps).to('cuda', dtype=torch.float) for inps in inputs)\n",
        "          optimizer.zero_grad()\n",
        "          embed1, embed2, embed3 = model(torch.unsqueeze(inputs[0], axis=0), torch.unsqueeze(inputs[1], axis=0), torch.unsqueeze(inputs[2], axis=0))\n",
        "          euclidean_distance = F.pairwise_distance(embed1, embed2)\n",
        "          min_dist = euclidean_distance\n",
        "          label_min = label1\n",
        "          for idx in range(len(embed_list)):\n",
        "              euc_dist = F.pairwise_distance(embed1, embed_list[idx][1])\n",
        "              if euc_dist < min_dist and embed_list[idx][0] != label1:\n",
        "                euc_dist += 0.3\n",
        "              if euc_dist < min_dist and euc_dist > 0.01:\n",
        "                  min_dist = euc_dist\n",
        "                  label_min = embed_list[idx][0]\n",
        "\n",
        "          if label_min == label1:\n",
        "            acc += 1\n",
        "        print(f\"Accuracy of {len(os.listdir(file_path))} different actors' images is: \" + str(acc / len(os.listdir(file_path)) * 100) + '%')"
      ],
      "metadata": {
        "id": "CjaII0eLVqHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FaceNet(embed_size=128, is_train=True)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/chckpnt8_embed128_lessData_model.pth\"))\n",
        "test_model(model, True, embed_list)"
      ],
      "metadata": {
        "id": "JTI7z0MCJJME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/chckpnt8_embed128_lessData_model.pth\"))\n",
        "file_path = '/content/test_set15'\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    euc_dist = 0\n",
        "    index = 17\n",
        "    imgFile1 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + '_0015.jpg'\n",
        "\n",
        "    imgFile2 = file_path + '/' + os.listdir(file_path)[index] + '/' + os.listdir(file_path)[index] + '_0003.jpg'\n",
        "    img1, label1 = np.array(Image.open(imgFile1), dtype='float32'), os.listdir(file_path)[index]\n",
        "    img2 = np.array(Image.open(imgFile2), dtype='float32')\n",
        "\n",
        "\n",
        "    img1 = np.transpose(img1, (2, 0, 1))\n",
        "    img2 = np.transpose(img2, (2, 0, 1))\n",
        "\n",
        "    \n",
        "    inputs = (img1, img2, img2)\n",
        "    if torch.cuda.is_available():\n",
        "      inputs = list(torch.tensor(inps).to('cuda', dtype=torch.float) for inps in inputs)\n",
        "    optimizer.zero_grad()\n",
        "    embed1, embed2, embed3 = model(torch.unsqueeze(inputs[0], axis=0), torch.unsqueeze(inputs[1], axis=0), torch.unsqueeze(inputs[2], axis=0))\n",
        "    euclidean_distance = F.pairwise_distance(embed1, embed2)\n",
        "    min_dist = euclidean_distance\n",
        "    best_min_dist = euclidean_distance\n",
        "    label_min = label1\n",
        "    best_correct_label = 0.\n",
        "    for idx in range(len(embed_list)):\n",
        "        euc_dist = F.pairwise_distance(embed1, embed_list[idx][1])\n",
        "        if euc_dist < best_min_dist and embed_list[idx][0] == label1 and euc_dist > 0.01:\n",
        "            best_min_dist = euc_dist\n",
        "            best_correct_label = euc_dist\n",
        "        if euc_dist < min_dist and embed_list[idx][0] != label1:\n",
        "            euc_dist += 0.01\n",
        "        if euc_dist < min_dist and euc_dist > 0.01:\n",
        "            min_dist = euc_dist\n",
        "            label_min, img_name = embed_list[idx][0], embed_list[idx][2]\n",
        "    name1, name2 = label1, label_min\n",
        "    text = f\"{name1} & {name2}\\nDiff_first: {euclidean_distance.item():.2f}\\nDiff_second: {min_dist.item():.2f}\"\n",
        "    try:\n",
        "      imgFile4 = '/content/train_set' + '/' + name2 + '/' + name2 + '_0001.jpg'\n",
        "      img4 = np.array(Image.open(imgFile4), dtype='float32')\n",
        "    except:\n",
        "      imgFile4 = 'negatives/' + name2 + '/' + name2 + '_0001.jpg'\n",
        "      img4 = np.array(Image.open(imgFile4), dtype='float32')\n",
        "    print(text, img_name, best_correct_label.item())\n",
        "    fig.add_subplot(2,2,1)\n",
        "    plt.imshow(Image.fromarray( np.asarray( np.clip(np.array(torch.permute(inputs[0], (1, 2, 0)).cpu()),0,255), dtype=\"uint8\"), \"RGB\" ))\n",
        "    #fig.add_subplot(2,3,2)\n",
        "    #plt.imshow(Image.fromarray( np.asarray( np.clip(np.array(torch.permute(inputs[1], (1, 2, 0)).cpu()),0,255), dtype=\"uint8\"), \"RGB\" ))\n",
        "    fig.add_subplot(2,2,2)\n",
        "    plt.imshow(Image.fromarray( np.asarray( np.clip(img4,0,255), dtype=\"uint8\"), \"RGB\" ))\n",
        "#plt.savefig('test-result.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DCXDPaOiKdrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# target_dir = r'/content/test_set9'\n",
        "# destination_dir = r'/content/test_set100'\n",
        "\n",
        "# for root_dir, cur_dir, files in os.walk(target_dir):\n",
        "#     if root_dir == target_dir: # avoid the target_dir for this check\n",
        "#         continue\n",
        "#     if len(files) >= 100:\n",
        "#         shutil.move(root_dir, destination_dir)"
      ],
      "metadata": {
        "id": "qaY2XHV5LzYg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r /content/test_set14.zip /content/test_set14"
      ],
      "metadata": {
        "id": "nawABykVYdYB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}