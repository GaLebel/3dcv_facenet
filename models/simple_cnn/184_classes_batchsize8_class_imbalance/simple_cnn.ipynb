{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy.io\n",
    "import math\n",
    "from keras.callbacks import CSVLogger\n",
    "import json\n",
    "\n",
    "\n",
    "# Option to see strings fully and not cut by ... in the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# \n",
    "# ```\n",
    "# df = dataframe\n",
    "# test_size = ratio of the test set (0.0 - 1.0)\n",
    "# batch_size = amount of pictures per class for the training set\n",
    "\n",
    "def split_data(data, test_size):\n",
    "    df = data\n",
    "    classes = df['actor_name'].unique()\n",
    "    test_names = []\n",
    "    train_names = []\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    for actor in classes:\n",
    "        actor_df = df[df['actor_name'] == actor]\n",
    "        images_number = len(actor_df)\n",
    "        train_size = math.ceil(images_number * (1 - test_size))\n",
    "        if train_size == 0:\n",
    "            train_size = 1\n",
    "        for i in range(images_number):\n",
    "            if i >= min(train_size, 9):\n",
    "                test_names.append(actor_df.iloc[i]['actor_name'])\n",
    "                test_paths.append(actor_df.iloc[i]['path'])\n",
    "                if i == 11:\n",
    "                    break\n",
    "            else:\n",
    "                train_names.append(actor_df.iloc[i]['actor_name'])\n",
    "                train_paths.append(actor_df.iloc[i]['path'])\n",
    "    train = np.vstack((train_names, train_paths))\n",
    "    test = np.vstack((test_names, test_paths))\n",
    "    train_set = pd.DataFrame(train).T\n",
    "    test_set = pd.DataFrame(test).T\n",
    "    \n",
    "    train_set.columns = ['actor_name', 'path']\n",
    "    test_set.columns = ['actor_name', 'path']\n",
    "    \n",
    "    return train_set, test_set\n",
    "            \n",
    "\n",
    "# function to remove actors that have less than 'n' images in the dataset\n",
    "\n",
    "def remove_single_occurrences(df, n):\n",
    "    count = df['actor_name'].value_counts()\n",
    "    mask = (count[df['actor_name']].values > n)\n",
    "    return df[mask]\n",
    "\n",
    "# function to load training & test sets into DataFrames\n",
    "def load_data(filename : str):\n",
    "    meta = pd.read_csv(filename).reset_index()\n",
    "    actors = meta['actor_name']\n",
    "    paths = meta['path']\n",
    "    meta = np.vstack((actors, paths))\n",
    "    meta_df = pd.DataFrame(meta).T\n",
    "    meta_df.columns = ['actor_name', 'path']\n",
    "    return meta_df\n",
    "\n",
    "#function to predict the class\n",
    "def predict_class(model : Sequential, train_gen, img_path, width, height):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    img = np.array(img)\n",
    "    \n",
    "    x_new = img.reshape(1, width, height, 4)\n",
    "    x_new = x_new.astype('float32') / 255\n",
    "    \n",
    "    predictions = model.predict(img)\n",
    "    \n",
    "    lookup_table = dict(map(reversed, train_gen.class_indices.items()))\n",
    "    \n",
    "    prediction = np.argmax(predictions)\n",
    "    \n",
    "    return(lookup_table[prediction])\n",
    "\n",
    "#function to save the train & test sets as well as the lookup table\n",
    "def save_info(train_gen, filename1, train_set, filename2, test_set, filename3):\n",
    "    lookup_table = dict(map(reversed, train_gen.class_indices.items()))\n",
    "    with open(filename1, 'w', encoding='utf8') as f:\n",
    "        json.dump(lookup_table, f)\n",
    "    train_set.to_csv(filename2)\n",
    "    test_set.to_csv(filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting up the meta data from the folder's structure of the LFW Dataset\n",
    "\n",
    "lfw_path = r'../../../data/lfw-deepfunneled'\n",
    "actor_list = []\n",
    "paths = []\n",
    "rest_actor_list = []\n",
    "rest_paths = []\n",
    "\n",
    "for root_dir, cur_dir, files in os.walk(lfw_path):\n",
    "    if root_dir == lfw_path:\n",
    "        continue\n",
    "    if len(files) >= 2:\n",
    "        actor_name = root_dir.replace(\"../../../data/lfw-deepfunneled\", \"\")\n",
    "        actor_name = actor_name.replace(\"\\\\\", \"\")\n",
    "        for idx, file in enumerate(files):\n",
    "            # if idx > 8:\n",
    "            #     rest_actor_list.append(actor_name)\n",
    "            #     rest_paths.append(lfw_path + \"\\\\\" + actor_name + \"\\\\\" + file)\n",
    "            actor_list.append(actor_name)\n",
    "            paths.append(lfw_path + \"\\\\\" + actor_name + \"\\\\\" + file)\n",
    "lfw = np.vstack((actor_list, paths))\n",
    "lfw_df = pd.DataFrame(lfw).T\n",
    "lfw_df.columns = ['actor_name', 'path']\n",
    "meta = lfw_df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>Gray_Davis</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Gray_Davis\\Gray_Davis_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>Gerhard_Schroeder</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Gerhard_Schroeder\\Gerhard_Schroeder_0067.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>Charles_Moose</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Charles_Moose\\Charles_Moose_0006.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Hun_Sen</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Hun_Sen\\Hun_Sen_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>Paula_Zahn</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Paula_Zahn\\Paula_Zahn_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>Ted_Maher</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Ted_Maher\\Ted_Maher_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>Toshihiko_Fukui</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Toshihiko_Fukui\\Toshihiko_Fukui_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8853</th>\n",
       "      <td>Vincent_Brooks</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Vincent_Brooks\\Vincent_Brooks_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>Tom_Ridge</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Tom_Ridge\\Tom_Ridge_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>Romano_Prodi</td>\n",
       "      <td>../../../data/lfw-deepfunneled\\Romano_Prodi\\Romano_Prodi_0007.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9166 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             actor_name  \\\n",
       "3393         Gray_Davis   \n",
       "3213  Gerhard_Schroeder   \n",
       "1288      Charles_Moose   \n",
       "3838            Hun_Sen   \n",
       "6905         Paula_Zahn   \n",
       "...                 ...   \n",
       "8264          Ted_Maher   \n",
       "8702    Toshihiko_Fukui   \n",
       "8853     Vincent_Brooks   \n",
       "8499          Tom_Ridge   \n",
       "7660       Romano_Prodi   \n",
       "\n",
       "                                                                             path  \n",
       "3393                ../../../data/lfw-deepfunneled\\Gray_Davis\\Gray_Davis_0002.jpg  \n",
       "3213  ../../../data/lfw-deepfunneled\\Gerhard_Schroeder\\Gerhard_Schroeder_0067.jpg  \n",
       "1288          ../../../data/lfw-deepfunneled\\Charles_Moose\\Charles_Moose_0006.jpg  \n",
       "3838                      ../../../data/lfw-deepfunneled\\Hun_Sen\\Hun_Sen_0004.jpg  \n",
       "6905                ../../../data/lfw-deepfunneled\\Paula_Zahn\\Paula_Zahn_0001.jpg  \n",
       "...                                                                           ...  \n",
       "8264                  ../../../data/lfw-deepfunneled\\Ted_Maher\\Ted_Maher_0002.jpg  \n",
       "8702      ../../../data/lfw-deepfunneled\\Toshihiko_Fukui\\Toshihiko_Fukui_0003.jpg  \n",
       "8853        ../../../data/lfw-deepfunneled\\Vincent_Brooks\\Vincent_Brooks_0003.jpg  \n",
       "8499                  ../../../data/lfw-deepfunneled\\Tom_Ridge\\Tom_Ridge_0003.jpg  \n",
       "7660            ../../../data/lfw-deepfunneled\\Romano_Prodi\\Romano_Prodi_0007.jpg  \n",
       "\n",
       "[9166 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_data('data\\lfw-deepfunneled\\metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: Abdullah_Gul, Max: Zhu_Rongji, Count: 184\n",
      "Found 3646 validated image filenames belonging to 184 classes.\n",
      "Found 912 validated image filenames belonging to 184 classes.\n",
      "Number of unique classes: 184\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# sort by actor_name and remove actors with less than 8 images\n",
    "new_meta = meta.sort_values(by=['actor_name'])\n",
    "data = new_meta\n",
    "data = remove_single_occurrences(data, 8)\n",
    "\n",
    "# check number of unique classes - probably can be removed\n",
    "unique_labels = data['actor_name'].unique()\n",
    "print(f\"Min: {min(unique_labels)}, Max: {max(unique_labels)}, Count: {len(unique_labels)}\")\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42, stratify = data['actor_name'])\n",
    "\n",
    "# Image preprocessing\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 8\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_set,\n",
    "    x_col='path',\n",
    "    y_col='actor_name',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    test_set,\n",
    "    x_col='path',\n",
    "    y_col='actor_name',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation = 'relu', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 132ms/step - loss: 5.1335 - accuracy: 0.1114 - val_loss: 4.7703 - val_accuracy: 0.1162\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 4.7701 - accuracy: 0.1155 - val_loss: 4.6398 - val_accuracy: 0.1162\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 4.6939 - accuracy: 0.1160 - val_loss: 4.6523 - val_accuracy: 0.1162\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 4.6114 - accuracy: 0.1188 - val_loss: 4.5158 - val_accuracy: 0.1261\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 4.5130 - accuracy: 0.1330 - val_loss: 4.4847 - val_accuracy: 0.1305\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 4.4092 - accuracy: 0.1404 - val_loss: 4.2472 - val_accuracy: 0.1502\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 4.2737 - accuracy: 0.1552 - val_loss: 4.1299 - val_accuracy: 0.1996\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 4.0760 - accuracy: 0.2021 - val_loss: 3.9101 - val_accuracy: 0.2412\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 3.8641 - accuracy: 0.2348 - val_loss: 3.7419 - val_accuracy: 0.2686\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 3.6438 - accuracy: 0.2803 - val_loss: 3.5934 - val_accuracy: 0.3136\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 3.4363 - accuracy: 0.3217 - val_loss: 3.3906 - val_accuracy: 0.3629\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 3.2420 - accuracy: 0.3618 - val_loss: 3.2623 - val_accuracy: 0.4024\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 3.1094 - accuracy: 0.3914 - val_loss: 3.1893 - val_accuracy: 0.4353\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 2.8886 - accuracy: 0.4336 - val_loss: 3.0732 - val_accuracy: 0.4276\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 2.7951 - accuracy: 0.4536 - val_loss: 3.0473 - val_accuracy: 0.4353\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 2.7035 - accuracy: 0.4663 - val_loss: 3.0532 - val_accuracy: 0.4792\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 2.6171 - accuracy: 0.4942 - val_loss: 3.0340 - val_accuracy: 0.4715\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 2.5340 - accuracy: 0.5066 - val_loss: 3.0099 - val_accuracy: 0.4879\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 2.5052 - accuracy: 0.5258 - val_loss: 3.0874 - val_accuracy: 0.4803\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 2.4577 - accuracy: 0.5403 - val_loss: 3.0072 - val_accuracy: 0.5022\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.3699 - accuracy: 0.5623 - val_loss: 2.9947 - val_accuracy: 0.5022\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 2.3096 - accuracy: 0.5787 - val_loss: 3.0175 - val_accuracy: 0.5099\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 2.3303 - accuracy: 0.5656 - val_loss: 3.1319 - val_accuracy: 0.4846\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.3037 - accuracy: 0.5826 - val_loss: 2.9907 - val_accuracy: 0.5033\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 2.2041 - accuracy: 0.6094 - val_loss: 3.0438 - val_accuracy: 0.5044\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 2.2129 - accuracy: 0.6081 - val_loss: 3.0482 - val_accuracy: 0.5044\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 2.1602 - accuracy: 0.6267 - val_loss: 2.9646 - val_accuracy: 0.5230\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 139ms/step - loss: 2.0976 - accuracy: 0.6289 - val_loss: 2.9635 - val_accuracy: 0.5340\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 2.1371 - accuracy: 0.6215 - val_loss: 3.0489 - val_accuracy: 0.5121\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.0885 - accuracy: 0.6418 - val_loss: 2.9799 - val_accuracy: 0.5296\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.0918 - accuracy: 0.6404 - val_loss: 3.0390 - val_accuracy: 0.5154\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.0006 - accuracy: 0.6659 - val_loss: 2.9779 - val_accuracy: 0.5175\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 2.0481 - accuracy: 0.6569 - val_loss: 3.0516 - val_accuracy: 0.5307\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.0787 - accuracy: 0.6514 - val_loss: 3.0917 - val_accuracy: 0.5373\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 2.0255 - accuracy: 0.6615 - val_loss: 2.9723 - val_accuracy: 0.5351\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 2.0099 - accuracy: 0.6646 - val_loss: 3.1364 - val_accuracy: 0.5274\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 139ms/step - loss: 1.9746 - accuracy: 0.6851 - val_loss: 3.0031 - val_accuracy: 0.5351\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.9790 - accuracy: 0.6816 - val_loss: 3.0206 - val_accuracy: 0.5208\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.9357 - accuracy: 0.6835 - val_loss: 2.9491 - val_accuracy: 0.5537\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.9274 - accuracy: 0.6947 - val_loss: 2.9528 - val_accuracy: 0.5439\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.9734 - accuracy: 0.6788 - val_loss: 3.0835 - val_accuracy: 0.5208\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.9307 - accuracy: 0.6978 - val_loss: 3.2069 - val_accuracy: 0.5340\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.9106 - accuracy: 0.6994 - val_loss: 3.0663 - val_accuracy: 0.5296\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.9040 - accuracy: 0.6956 - val_loss: 3.0290 - val_accuracy: 0.5471\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.8948 - accuracy: 0.7016 - val_loss: 3.1070 - val_accuracy: 0.5406\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.8822 - accuracy: 0.7002 - val_loss: 2.9831 - val_accuracy: 0.5702\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.8702 - accuracy: 0.7041 - val_loss: 3.0678 - val_accuracy: 0.5285\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.8482 - accuracy: 0.7032 - val_loss: 3.0948 - val_accuracy: 0.5406\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.8679 - accuracy: 0.7082 - val_loss: 2.9172 - val_accuracy: 0.5581\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.8572 - accuracy: 0.7041 - val_loss: 2.9260 - val_accuracy: 0.5789\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 136ms/step - loss: 1.8457 - accuracy: 0.7095 - val_loss: 3.1515 - val_accuracy: 0.5570\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.8295 - accuracy: 0.7128 - val_loss: 3.0009 - val_accuracy: 0.5702\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.8847 - accuracy: 0.7104 - val_loss: 2.9751 - val_accuracy: 0.5724\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.7724 - accuracy: 0.7307 - val_loss: 3.1119 - val_accuracy: 0.5581\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.7974 - accuracy: 0.7265 - val_loss: 3.0717 - val_accuracy: 0.5461\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.7859 - accuracy: 0.7359 - val_loss: 3.0662 - val_accuracy: 0.5461\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.7626 - accuracy: 0.7403 - val_loss: 3.0036 - val_accuracy: 0.5658\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.7649 - accuracy: 0.7312 - val_loss: 2.9924 - val_accuracy: 0.5537\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.7331 - accuracy: 0.7416 - val_loss: 2.8910 - val_accuracy: 0.5746\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.7770 - accuracy: 0.7252 - val_loss: 2.8898 - val_accuracy: 0.5757\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.7956 - accuracy: 0.7233 - val_loss: 3.0136 - val_accuracy: 0.5548\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.7754 - accuracy: 0.7381 - val_loss: 3.0184 - val_accuracy: 0.5603\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.7577 - accuracy: 0.7353 - val_loss: 3.0349 - val_accuracy: 0.5482\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.7374 - accuracy: 0.7438 - val_loss: 3.0483 - val_accuracy: 0.5822\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.7812 - accuracy: 0.7255 - val_loss: 3.1468 - val_accuracy: 0.5384\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.7233 - accuracy: 0.7457 - val_loss: 2.9168 - val_accuracy: 0.5625\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.7222 - accuracy: 0.7400 - val_loss: 2.9823 - val_accuracy: 0.5592\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 139ms/step - loss: 1.7471 - accuracy: 0.7364 - val_loss: 2.9115 - val_accuracy: 0.5724\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 137ms/step - loss: 1.7170 - accuracy: 0.7403 - val_loss: 2.9749 - val_accuracy: 0.5603\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.7731 - accuracy: 0.7403 - val_loss: 2.9223 - val_accuracy: 0.5691\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 133ms/step - loss: 1.7251 - accuracy: 0.7447 - val_loss: 2.9986 - val_accuracy: 0.5658\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.7192 - accuracy: 0.7383 - val_loss: 3.0428 - val_accuracy: 0.5822\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.6995 - accuracy: 0.7537 - val_loss: 2.9412 - val_accuracy: 0.5822\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6977 - accuracy: 0.7468 - val_loss: 2.9608 - val_accuracy: 0.5866\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6770 - accuracy: 0.7622 - val_loss: 2.9785 - val_accuracy: 0.5789\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6976 - accuracy: 0.7537 - val_loss: 2.9432 - val_accuracy: 0.5680\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.7047 - accuracy: 0.7449 - val_loss: 2.8903 - val_accuracy: 0.5724\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.7035 - accuracy: 0.7501 - val_loss: 3.0482 - val_accuracy: 0.5559\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6504 - accuracy: 0.7603 - val_loss: 3.1404 - val_accuracy: 0.5669\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6932 - accuracy: 0.7567 - val_loss: 2.9583 - val_accuracy: 0.5526\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6929 - accuracy: 0.7526 - val_loss: 3.1088 - val_accuracy: 0.5680\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6513 - accuracy: 0.7562 - val_loss: 2.9112 - val_accuracy: 0.5877\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6309 - accuracy: 0.7633 - val_loss: 2.9845 - val_accuracy: 0.5789\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6566 - accuracy: 0.7595 - val_loss: 2.9423 - val_accuracy: 0.5910\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6603 - accuracy: 0.7545 - val_loss: 2.9960 - val_accuracy: 0.5899\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6490 - accuracy: 0.7578 - val_loss: 3.0743 - val_accuracy: 0.5592\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6401 - accuracy: 0.7603 - val_loss: 3.1206 - val_accuracy: 0.5800\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6557 - accuracy: 0.7597 - val_loss: 3.0042 - val_accuracy: 0.5910\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6237 - accuracy: 0.7732 - val_loss: 2.9790 - val_accuracy: 0.5680\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6273 - accuracy: 0.7682 - val_loss: 2.9346 - val_accuracy: 0.5724\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6568 - accuracy: 0.7597 - val_loss: 3.1124 - val_accuracy: 0.5954\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6700 - accuracy: 0.7573 - val_loss: 2.9448 - val_accuracy: 0.5735\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6524 - accuracy: 0.7600 - val_loss: 2.9191 - val_accuracy: 0.5800\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6502 - accuracy: 0.7636 - val_loss: 2.9639 - val_accuracy: 0.6009\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6537 - accuracy: 0.7671 - val_loss: 2.9740 - val_accuracy: 0.5757\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5885 - accuracy: 0.7795 - val_loss: 2.9273 - val_accuracy: 0.5779\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6182 - accuracy: 0.7633 - val_loss: 2.9781 - val_accuracy: 0.6053\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.6315 - accuracy: 0.7639 - val_loss: 2.9149 - val_accuracy: 0.5888\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6227 - accuracy: 0.7641 - val_loss: 3.0075 - val_accuracy: 0.5691\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5596 - accuracy: 0.7855 - val_loss: 3.0123 - val_accuracy: 0.5921\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5645 - accuracy: 0.7795 - val_loss: 2.9774 - val_accuracy: 0.5855\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5766 - accuracy: 0.7773 - val_loss: 3.0653 - val_accuracy: 0.5943\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5768 - accuracy: 0.7811 - val_loss: 2.9894 - val_accuracy: 0.5768\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5610 - accuracy: 0.7839 - val_loss: 3.0301 - val_accuracy: 0.5877\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5476 - accuracy: 0.7809 - val_loss: 3.1171 - val_accuracy: 0.5811\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.5788 - accuracy: 0.7765 - val_loss: 3.0785 - val_accuracy: 0.5866\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5989 - accuracy: 0.7699 - val_loss: 2.9913 - val_accuracy: 0.6096\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.6042 - accuracy: 0.7740 - val_loss: 2.8989 - val_accuracy: 0.5998\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5572 - accuracy: 0.7894 - val_loss: 2.9958 - val_accuracy: 0.5921\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5731 - accuracy: 0.7830 - val_loss: 3.0337 - val_accuracy: 0.6118\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5829 - accuracy: 0.7735 - val_loss: 3.0581 - val_accuracy: 0.5976\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5850 - accuracy: 0.7765 - val_loss: 2.9387 - val_accuracy: 0.5998\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5710 - accuracy: 0.7770 - val_loss: 2.9217 - val_accuracy: 0.5976\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5615 - accuracy: 0.7795 - val_loss: 2.8973 - val_accuracy: 0.6140\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.5624 - accuracy: 0.7844 - val_loss: 2.9167 - val_accuracy: 0.5811\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5689 - accuracy: 0.7891 - val_loss: 2.9791 - val_accuracy: 0.5888\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.5455 - accuracy: 0.7905 - val_loss: 2.9497 - val_accuracy: 0.5976\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.6029 - accuracy: 0.7792 - val_loss: 2.9097 - val_accuracy: 0.6162\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.5243 - accuracy: 0.7998 - val_loss: 2.9051 - val_accuracy: 0.6162\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5579 - accuracy: 0.7880 - val_loss: 2.9042 - val_accuracy: 0.5965\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.5128 - accuracy: 0.7907 - val_loss: 2.9644 - val_accuracy: 0.6020\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.5060 - accuracy: 0.7998 - val_loss: 2.9435 - val_accuracy: 0.6294\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5178 - accuracy: 0.7943 - val_loss: 2.9754 - val_accuracy: 0.5921\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5649 - accuracy: 0.7844 - val_loss: 2.9504 - val_accuracy: 0.5921\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 135ms/step - loss: 1.5375 - accuracy: 0.7888 - val_loss: 2.9682 - val_accuracy: 0.5965\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.5412 - accuracy: 0.7913 - val_loss: 2.9490 - val_accuracy: 0.6020\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 62s 135ms/step - loss: 1.4875 - accuracy: 0.7962 - val_loss: 3.0344 - val_accuracy: 0.5932\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5152 - accuracy: 0.7921 - val_loss: 2.9533 - val_accuracy: 0.5779\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5096 - accuracy: 0.7970 - val_loss: 3.0079 - val_accuracy: 0.6064\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 61s 133ms/step - loss: 1.5647 - accuracy: 0.7910 - val_loss: 2.9916 - val_accuracy: 0.5713\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.5264 - accuracy: 0.7951 - val_loss: 3.0479 - val_accuracy: 0.5855\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 61s 133ms/step - loss: 1.4999 - accuracy: 0.7995 - val_loss: 2.9784 - val_accuracy: 0.5855\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 61s 134ms/step - loss: 1.4826 - accuracy: 0.7984 - val_loss: 2.9764 - val_accuracy: 0.5899\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 63s 138ms/step - loss: 1.4832 - accuracy: 0.8039 - val_loss: 2.8842 - val_accuracy: 0.6184\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 63s 137ms/step - loss: 1.5506 - accuracy: 0.7825 - val_loss: 2.9102 - val_accuracy: 0.5888\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 82s 181ms/step - loss: 1.5097 - accuracy: 0.8003 - val_loss: 3.0381 - val_accuracy: 0.6118\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 85s 186ms/step - loss: 1.5212 - accuracy: 0.7981 - val_loss: 2.9584 - val_accuracy: 0.6107\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 87s 191ms/step - loss: 1.4534 - accuracy: 0.8151 - val_loss: 2.9455 - val_accuracy: 0.6086\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 84s 185ms/step - loss: 1.4868 - accuracy: 0.7979 - val_loss: 3.0507 - val_accuracy: 0.6009\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 67s 146ms/step - loss: 1.4791 - accuracy: 0.8009 - val_loss: 2.9784 - val_accuracy: 0.6129\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 70s 153ms/step - loss: 1.4796 - accuracy: 0.8020 - val_loss: 2.8979 - val_accuracy: 0.6020\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 51s 111ms/step - loss: 1.4688 - accuracy: 0.8022 - val_loss: 2.9475 - val_accuracy: 0.5987\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 48s 104ms/step - loss: 1.5135 - accuracy: 0.7926 - val_loss: 2.9601 - val_accuracy: 0.6009\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 48s 105ms/step - loss: 1.4629 - accuracy: 0.8129 - val_loss: 2.9367 - val_accuracy: 0.5921\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 48s 105ms/step - loss: 1.4723 - accuracy: 0.7998 - val_loss: 2.9382 - val_accuracy: 0.5954\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 48s 104ms/step - loss: 1.4476 - accuracy: 0.8116 - val_loss: 2.8629 - val_accuracy: 0.6206\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 48s 105ms/step - loss: 1.4579 - accuracy: 0.8091 - val_loss: 3.0270 - val_accuracy: 0.5888\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 47s 104ms/step - loss: 1.5092 - accuracy: 0.7981 - val_loss: 2.9665 - val_accuracy: 0.6020\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 48s 104ms/step - loss: 1.4594 - accuracy: 0.8132 - val_loss: 3.0487 - val_accuracy: 0.5910\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 48s 105ms/step - loss: 1.4761 - accuracy: 0.8031 - val_loss: 2.9981 - val_accuracy: 0.6053\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 47s 104ms/step - loss: 1.5001 - accuracy: 0.8094 - val_loss: 3.0235 - val_accuracy: 0.6162\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 47s 103ms/step - loss: 1.4719 - accuracy: 0.8066 - val_loss: 2.8470 - val_accuracy: 0.6020\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 47s 103ms/step - loss: 1.4579 - accuracy: 0.8149 - val_loss: 3.1988 - val_accuracy: 0.5855\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 46s 102ms/step - loss: 1.4906 - accuracy: 0.8012 - val_loss: 2.9709 - val_accuracy: 0.5987\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 46s 101ms/step - loss: 1.4580 - accuracy: 0.8069 - val_loss: 2.8906 - val_accuracy: 0.6042\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4359 - accuracy: 0.8033 - val_loss: 2.9701 - val_accuracy: 0.5932\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 44s 96ms/step - loss: 1.4524 - accuracy: 0.8080 - val_loss: 2.9716 - val_accuracy: 0.5976\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4976 - accuracy: 0.8017 - val_loss: 3.0250 - val_accuracy: 0.5746\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4247 - accuracy: 0.8102 - val_loss: 2.9075 - val_accuracy: 0.6107\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4593 - accuracy: 0.8094 - val_loss: 2.9130 - val_accuracy: 0.6009\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4707 - accuracy: 0.8055 - val_loss: 2.9034 - val_accuracy: 0.6086\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 44s 96ms/step - loss: 1.4710 - accuracy: 0.8047 - val_loss: 3.0294 - val_accuracy: 0.5954\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4734 - accuracy: 0.8022 - val_loss: 3.1384 - val_accuracy: 0.5866\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4905 - accuracy: 0.8094 - val_loss: 2.9414 - val_accuracy: 0.6042\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4682 - accuracy: 0.8091 - val_loss: 2.9400 - val_accuracy: 0.6053\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4261 - accuracy: 0.8135 - val_loss: 2.9933 - val_accuracy: 0.6129\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 44s 96ms/step - loss: 1.4107 - accuracy: 0.8239 - val_loss: 3.1353 - val_accuracy: 0.6075\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4285 - accuracy: 0.8193 - val_loss: 2.8992 - val_accuracy: 0.6053\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4061 - accuracy: 0.8138 - val_loss: 3.0026 - val_accuracy: 0.6129\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4354 - accuracy: 0.8108 - val_loss: 3.0653 - val_accuracy: 0.5976\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4316 - accuracy: 0.8088 - val_loss: 3.2696 - val_accuracy: 0.5779\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4755 - accuracy: 0.8099 - val_loss: 3.1428 - val_accuracy: 0.6009\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4464 - accuracy: 0.8080 - val_loss: 2.8863 - val_accuracy: 0.5965\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4522 - accuracy: 0.8058 - val_loss: 3.0533 - val_accuracy: 0.5987\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4096 - accuracy: 0.8193 - val_loss: 3.0928 - val_accuracy: 0.6162\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 44s 96ms/step - loss: 1.4392 - accuracy: 0.8121 - val_loss: 2.9729 - val_accuracy: 0.5987\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4190 - accuracy: 0.8135 - val_loss: 3.0859 - val_accuracy: 0.5877\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.3990 - accuracy: 0.8228 - val_loss: 3.0169 - val_accuracy: 0.6206\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.3783 - accuracy: 0.8313 - val_loss: 3.2383 - val_accuracy: 0.5811\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4083 - accuracy: 0.8173 - val_loss: 3.0985 - val_accuracy: 0.5976\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4356 - accuracy: 0.8102 - val_loss: 3.0758 - val_accuracy: 0.6053\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4264 - accuracy: 0.8080 - val_loss: 3.0290 - val_accuracy: 0.6107\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4662 - accuracy: 0.8077 - val_loss: 3.1264 - val_accuracy: 0.5965\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4411 - accuracy: 0.8086 - val_loss: 2.9591 - val_accuracy: 0.5932\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4078 - accuracy: 0.8173 - val_loss: 2.9968 - val_accuracy: 0.6086\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.3977 - accuracy: 0.8253 - val_loss: 2.9953 - val_accuracy: 0.6107\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4311 - accuracy: 0.8105 - val_loss: 2.8806 - val_accuracy: 0.6184\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.3621 - accuracy: 0.8272 - val_loss: 3.1205 - val_accuracy: 0.6107\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 44s 96ms/step - loss: 1.3739 - accuracy: 0.8190 - val_loss: 2.9753 - val_accuracy: 0.6009\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 95ms/step - loss: 1.4156 - accuracy: 0.8195 - val_loss: 3.0441 - val_accuracy: 0.6107\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4490 - accuracy: 0.8127 - val_loss: 2.9578 - val_accuracy: 0.6107\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 42s 91ms/step - loss: 1.3938 - accuracy: 0.8269 - val_loss: 3.1997 - val_accuracy: 0.6020\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 43s 93ms/step - loss: 1.4038 - accuracy: 0.8140 - val_loss: 3.0764 - val_accuracy: 0.6184\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4451 - accuracy: 0.8132 - val_loss: 3.2614 - val_accuracy: 0.5866\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4719 - accuracy: 0.8086 - val_loss: 3.0930 - val_accuracy: 0.5866\n",
      "Epoch 1/5\n",
      "456/456 [==============================] - 42s 93ms/step - loss: 1.4065 - accuracy: 0.8220 - val_loss: 3.0925 - val_accuracy: 0.5855\n",
      "Epoch 2/5\n",
      "456/456 [==============================] - 43s 93ms/step - loss: 1.3621 - accuracy: 0.8289 - val_loss: 3.1129 - val_accuracy: 0.6075\n",
      "Epoch 3/5\n",
      "456/456 [==============================] - 42s 93ms/step - loss: 1.3452 - accuracy: 0.8278 - val_loss: 3.0736 - val_accuracy: 0.5899\n",
      "Epoch 4/5\n",
      "456/456 [==============================] - 43s 94ms/step - loss: 1.4197 - accuracy: 0.8157 - val_loss: 3.2528 - val_accuracy: 0.5932\n",
      "Epoch 5/5\n",
      "456/456 [==============================] - 43s 93ms/step - loss: 1.3945 - accuracy: 0.8242 - val_loss: 3.1195 - val_accuracy: 0.6042\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# since we've experienced crashes during the training, \n",
    "#we made the training in a for loop where every 5 epochs we save the model and output the log into a csv file\n",
    "\n",
    "epochs = 200\n",
    "for i in range(0,40):        \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=int(epochs/40),\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator))\n",
    "    \n",
    "    ## save stuff after 5 epochs\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = str(batch_size) + '_history_' + str(i+1 * 5) + \".csv\"\n",
    "    with open('history/' + hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    model.save(str(batch_size) + '_epoch' + str(i+1 * 5) + '.h5')\n",
    "\n",
    "# Save the trained model\n",
    "model.save(str(batch_size) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info(train_generator, \"lookup_table.json\", train_set, \"train_set.csv\", test_set, \"test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shit\n"
     ]
    }
   ],
   "source": [
    "print(\"shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
