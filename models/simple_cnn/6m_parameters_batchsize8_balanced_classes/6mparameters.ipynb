{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy.io\n",
    "import math\n",
    "from keras.callbacks import CSVLogger\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Option to see strings fully and not cut by ... in the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# \n",
    "# ```\n",
    "# df = dataframe\n",
    "# test_size = ratio of the test set (0.0 - 1.0)\n",
    "# batch_size = amount of pictures per class for the training set\n",
    "\n",
    "def split_data(data, test_size):\n",
    "    df = data\n",
    "    classes = df['actor_name'].unique()\n",
    "    test_names = []\n",
    "    train_names = []\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    for actor in classes:\n",
    "        actor_df = df[df['actor_name'] == actor]\n",
    "        images_number = len(actor_df)\n",
    "        train_size = math.ceil(images_number * (1 - test_size))\n",
    "        if train_size == 0:\n",
    "            train_size = 1\n",
    "        for i in range(images_number):\n",
    "            if i >= min(train_size, 9):\n",
    "                test_names.append(actor_df.iloc[i]['actor_name'])\n",
    "                test_paths.append(actor_df.iloc[i]['path'])\n",
    "                if i == 11:\n",
    "                    break\n",
    "            else:\n",
    "                train_names.append(actor_df.iloc[i]['actor_name'])\n",
    "                train_paths.append(actor_df.iloc[i]['path'])\n",
    "    train = np.vstack((train_names, train_paths))\n",
    "    test = np.vstack((test_names, test_paths))\n",
    "    train_set = pd.DataFrame(train).T\n",
    "    test_set = pd.DataFrame(test).T\n",
    "    \n",
    "    train_set.columns = ['actor_name', 'path']\n",
    "    test_set.columns = ['actor_name', 'path']\n",
    "    \n",
    "    return train_set, test_set\n",
    "            \n",
    "\n",
    "# function to remove actors that have less than 'n' images in the dataset\n",
    "\n",
    "def remove_single_occurrences(df, n):\n",
    "    count = df['actor_name'].value_counts()\n",
    "    mask = (count[df['actor_name']].values > n)\n",
    "    return df[mask]\n",
    "\n",
    "def remove_single_occurrences2(df, n):\n",
    "    count = df['actor_name'].value_counts()\n",
    "    mask = (count[df['actor_name']].values < n)\n",
    "    return df[mask]\n",
    "\n",
    "# function to load training & test sets into DataFrames\n",
    "def load_data(filename : str):\n",
    "    meta = pd.read_csv(filename).reset_index()\n",
    "    actors = meta['actor_name']\n",
    "    paths = meta['path']\n",
    "    meta = np.vstack((actors, paths))\n",
    "    meta_df = pd.DataFrame(meta).T\n",
    "    meta_df.columns = ['actor_name', 'path']\n",
    "    return meta_df\n",
    "\n",
    "#function to predict the class\n",
    "# predict a class using img file\n",
    "def predict_class(filepath):\n",
    "    import cv2\n",
    "    img = cv2.imread(filepath)\n",
    "    resized_img = cv2.resize(img, (128, 128))\n",
    "    normalizedImg = np.zeros((800, 800))\n",
    "    normalizedImg = cv2.normalize(resized_img, normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "    resized_img = normalizedImg.reshape(1, 128, 128, 3)\n",
    "    return lookup_table[str(np.argmax(model.predict(resized_img)))]\n",
    "\n",
    "def sample_till(df, maxo):\n",
    "    names = train_set['actor_name'].unique()\n",
    "    names_list = []\n",
    "    paths_list = []\n",
    "    for name in names:\n",
    "        paths = df[df['actor_name'] == name]['path']\n",
    "        for i, path in enumerate(paths):\n",
    "            if i > min(len(paths), maxo):\n",
    "                break\n",
    "            names_list.append(name)\n",
    "            paths_list.append(path)\n",
    "            \n",
    "    df_new = np.vstack((names_list, paths_list))\n",
    "    df = pd.DataFrame(df_new).T\n",
    "    df.columns = ['actor_name', 'path']\n",
    "    df = df.sample(frac = 1)\n",
    "    return df\n",
    "\n",
    "#function to save the train & test sets as well as the lookup table\n",
    "def save_info(train_gen, filename1, train_set, filename2, test_set, filename3):\n",
    "    lookup_table = dict(map(reversed, train_gen.class_indices.items()))\n",
    "    with open(filename1, 'w', encoding='utf8') as f:\n",
    "        json.dump(lookup_table, f)\n",
    "    train_set.to_csv(filename2)\n",
    "    test_set.to_csv(filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data of train & test sets from earlier training of this model\n",
    "train_set = load_data(r'train_set.csv')\n",
    "test_set = load_data(r'test_set.csv')\n",
    "lookup_table = {}\n",
    "with open('lookup_table.json', 'r') as f:\n",
    "    lookup_table = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = remove_single_occurrences(train_set, 8)\n",
    "train_set = remove_single_occurrences2(train_set, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2734 validated image filenames belonging to 179 classes.\n",
      "Found 684 validated image filenames belonging to 179 classes.\n",
      "Number of unique classes: 179\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# sort by actor_name and remove actors with less than 8 images\n",
    "new_meta = meta.sort_values(by=['actor_name'])\n",
    "data = new_meta\n",
    "data = remove_single_occurrences(data, 25)\n",
    "\n",
    "#Splitting into train and validation sets - can be commeneted out if loading the sets from csv\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42, stratify = data['actor_name'])\n",
    "\n",
    "#Image preprocessing\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 8\n",
    "#Normalizing the images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#Creating the generators for training and test\\validation sets\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_set,\n",
    "    x_col='path',\n",
    "    y_col='actor_name',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    test_set,\n",
    "    x_col='path',\n",
    "    y_col='actor_name',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "#Printing number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation = 'relu', kernel_regularizer='l2'),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#Compiling the model\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_46 (Conv2D)          (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 63, 63, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 30, 30, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 256)               6422784   \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 179)               46003     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,562,035\n",
      "Trainable params: 6,562,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "342/342 [==============================] - 43s 122ms/step - loss: 5.3083 - accuracy: 0.0172 - val_loss: 5.0622 - val_accuracy: 0.0219\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 5.0817 - accuracy: 0.0223 - val_loss: 5.0416 - val_accuracy: 0.0234\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 49s 144ms/step - loss: 5.0265 - accuracy: 0.0347 - val_loss: 4.9688 - val_accuracy: 0.0409\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 49s 144ms/step - loss: 4.7826 - accuracy: 0.0538 - val_loss: 4.7031 - val_accuracy: 0.0556\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 4.4661 - accuracy: 0.0922 - val_loss: 4.5321 - val_accuracy: 0.0731\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 49s 144ms/step - loss: 4.1089 - accuracy: 0.1335 - val_loss: 4.2904 - val_accuracy: 0.1140\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 49s 144ms/step - loss: 3.7896 - accuracy: 0.1873 - val_loss: 4.2191 - val_accuracy: 0.1550\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 50s 145ms/step - loss: 3.4505 - accuracy: 0.2542 - val_loss: 4.2129 - val_accuracy: 0.1564\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 49s 144ms/step - loss: 3.1026 - accuracy: 0.3171 - val_loss: 4.1386 - val_accuracy: 0.1842\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 50s 145ms/step - loss: 2.7951 - accuracy: 0.3950 - val_loss: 4.4064 - val_accuracy: 0.1754\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 49s 144ms/step - loss: 2.5297 - accuracy: 0.4448 - val_loss: 4.3518 - val_accuracy: 0.2178\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 2.2192 - accuracy: 0.5252 - val_loss: 4.5120 - val_accuracy: 0.2354\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 2.0148 - accuracy: 0.5856 - val_loss: 4.8186 - val_accuracy: 0.2573\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 49s 145ms/step - loss: 1.8531 - accuracy: 0.6485 - val_loss: 5.0105 - val_accuracy: 0.2368\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 1.6254 - accuracy: 0.7151 - val_loss: 5.6181 - val_accuracy: 0.2515\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 1.5094 - accuracy: 0.7414 - val_loss: 5.5183 - val_accuracy: 0.2646\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 1.4542 - accuracy: 0.7601 - val_loss: 5.6841 - val_accuracy: 0.2749\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 1.2871 - accuracy: 0.8146 - val_loss: 5.7962 - val_accuracy: 0.2690\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 1.2118 - accuracy: 0.8248 - val_loss: 6.0375 - val_accuracy: 0.2646\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 1.2267 - accuracy: 0.8252 - val_loss: 6.1952 - val_accuracy: 0.2749\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 1.1372 - accuracy: 0.8486 - val_loss: 6.2635 - val_accuracy: 0.2558\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 139ms/step - loss: 1.1435 - accuracy: 0.8416 - val_loss: 6.6525 - val_accuracy: 0.2719\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 139ms/step - loss: 1.1311 - accuracy: 0.8449 - val_loss: 6.9451 - val_accuracy: 0.2558\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 1.0477 - accuracy: 0.8705 - val_loss: 6.6222 - val_accuracy: 0.2705\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.9238 - accuracy: 0.9053 - val_loss: 6.9242 - val_accuracy: 0.2675\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 142ms/step - loss: 1.0772 - accuracy: 0.8570 - val_loss: 6.7177 - val_accuracy: 0.2836\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.9491 - accuracy: 0.8994 - val_loss: 7.0698 - val_accuracy: 0.2836\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 139ms/step - loss: 0.9473 - accuracy: 0.8947 - val_loss: 7.4364 - val_accuracy: 0.2690\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.9312 - accuracy: 0.8954 - val_loss: 7.2346 - val_accuracy: 0.2500\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.9798 - accuracy: 0.8917 - val_loss: 7.3184 - val_accuracy: 0.2675\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 1.0378 - accuracy: 0.8709 - val_loss: 7.2464 - val_accuracy: 0.2588\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 139ms/step - loss: 0.9170 - accuracy: 0.9104 - val_loss: 7.0149 - val_accuracy: 0.3056\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 139ms/step - loss: 0.8659 - accuracy: 0.9206 - val_loss: 8.2076 - val_accuracy: 0.2836\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.8970 - accuracy: 0.9056 - val_loss: 7.2009 - val_accuracy: 0.2836\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.9378 - accuracy: 0.8950 - val_loss: 6.7858 - val_accuracy: 0.3158\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 142ms/step - loss: 0.9256 - accuracy: 0.9038 - val_loss: 6.9447 - val_accuracy: 0.2822\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.8931 - accuracy: 0.9239 - val_loss: 6.9569 - val_accuracy: 0.3246\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 0.8207 - accuracy: 0.9334 - val_loss: 6.8519 - val_accuracy: 0.2909\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 0.8768 - accuracy: 0.9086 - val_loss: 6.4400 - val_accuracy: 0.2822\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 0.8891 - accuracy: 0.9016 - val_loss: 7.5697 - val_accuracy: 0.2690\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.9388 - accuracy: 0.9023 - val_loss: 7.2908 - val_accuracy: 0.3012\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 47s 138ms/step - loss: 0.8732 - accuracy: 0.9148 - val_loss: 6.8219 - val_accuracy: 0.3114\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.7745 - accuracy: 0.9477 - val_loss: 6.8406 - val_accuracy: 0.3012\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 47s 138ms/step - loss: 0.8243 - accuracy: 0.9221 - val_loss: 7.2814 - val_accuracy: 0.3173\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 142ms/step - loss: 0.8155 - accuracy: 0.9206 - val_loss: 7.4066 - val_accuracy: 0.3216\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.9104 - accuracy: 0.9060 - val_loss: 6.8547 - val_accuracy: 0.2836\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.8184 - accuracy: 0.9232 - val_loss: 6.6436 - val_accuracy: 0.3085\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 47s 139ms/step - loss: 0.7376 - accuracy: 0.9459 - val_loss: 7.2510 - val_accuracy: 0.2953\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.7468 - accuracy: 0.9356 - val_loss: 7.5383 - val_accuracy: 0.3041\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.8543 - accuracy: 0.9053 - val_loss: 6.9883 - val_accuracy: 0.3012\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 0.8214 - accuracy: 0.9279 - val_loss: 6.8571 - val_accuracy: 0.3246\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 0.8098 - accuracy: 0.9279 - val_loss: 6.7941 - val_accuracy: 0.3143\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 0.7992 - accuracy: 0.9261 - val_loss: 6.4965 - val_accuracy: 0.3260\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 0.7450 - accuracy: 0.9400 - val_loss: 7.0184 - val_accuracy: 0.3304\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.7584 - accuracy: 0.9404 - val_loss: 7.4897 - val_accuracy: 0.2880\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.8286 - accuracy: 0.9184 - val_loss: 6.6326 - val_accuracy: 0.3099\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.7647 - accuracy: 0.9371 - val_loss: 6.6286 - val_accuracy: 0.3289\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.6844 - accuracy: 0.9517 - val_loss: 6.8740 - val_accuracy: 0.3260\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 47s 138ms/step - loss: 0.7909 - accuracy: 0.9166 - val_loss: 6.8531 - val_accuracy: 0.3494\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 47s 138ms/step - loss: 0.8217 - accuracy: 0.9254 - val_loss: 6.7251 - val_accuracy: 0.3377\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 47s 138ms/step - loss: 0.8110 - accuracy: 0.9236 - val_loss: 6.5721 - val_accuracy: 0.3246\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 139ms/step - loss: 0.7835 - accuracy: 0.9331 - val_loss: 6.5007 - val_accuracy: 0.3289\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.7348 - accuracy: 0.9466 - val_loss: 6.6174 - val_accuracy: 0.3304\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.7057 - accuracy: 0.9492 - val_loss: 6.4696 - val_accuracy: 0.3406\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 48s 140ms/step - loss: 0.8752 - accuracy: 0.8980 - val_loss: 6.1133 - val_accuracy: 0.3860\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 48s 142ms/step - loss: 0.7446 - accuracy: 0.9418 - val_loss: 6.3777 - val_accuracy: 0.3465\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 48s 141ms/step - loss: 0.6868 - accuracy: 0.9539 - val_loss: 6.7448 - val_accuracy: 0.3596\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 0.6727 - accuracy: 0.9528 - val_loss: 6.3206 - val_accuracy: 0.3582\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 49s 142ms/step - loss: 0.8045 - accuracy: 0.9170 - val_loss: 6.5676 - val_accuracy: 0.3173\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 49s 143ms/step - loss: 0.7520 - accuracy: 0.9382 - val_loss: 6.6427 - val_accuracy: 0.3392\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 50s 147ms/step - loss: 0.7068 - accuracy: 0.9488 - val_loss: 6.2397 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      " 88/342 [======>.......................] - ETA: 34s - loss: 0.6183 - accuracy: 0.9830"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m80\u001b[39m):        \n\u001b[1;32m----> 7\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      8\u001b[0m         train_generator,\n\u001b[0;32m      9\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_generator),\n\u001b[0;32m     10\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(epochs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m80\u001b[39m),\n\u001b[0;32m     11\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[0;32m     12\u001b[0m         validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_generator))\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m## save stuff after 5 epochs\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     hist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# since we've experienced crashes during the training, \n",
    "#we made the training in a for loop where every 5 epochs we save the model and output the log into a csv file\n",
    "\n",
    "epochs = 400\n",
    "for i in range(0,80):        \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=int(epochs/80),\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator))\n",
    "    \n",
    "    ## save stuff after 5 epochs\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = str(batch_size) + '_history_' + str((i+1) * 5) + \".csv\"\n",
    "    with open(\"2nd/\" + hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    model.save(\"2nd/\" + str(batch_size) + '_epoch' + str((i+1) * 5) + '.h5')\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"2nd/\" + str(batch_size) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info(train_generator, \"lookup_table_train_generator.txt\", train_set, \"train_set.csv\", test_set, \"test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 126, 126, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 63, 63, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 61, 61, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 30, 30, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                401472    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 179)               11635     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 419,139\n",
      "Trainable params: 419,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
