{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy.io\n",
    "import math\n",
    "from keras.callbacks import CSVLogger\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Option to see strings fully and not cut by ... in the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# \n",
    "# ```\n",
    "# df = dataframe\n",
    "# test_size = ratio of the test set (0.0 - 1.0)\n",
    "# batch_size = amount of pictures per class for the training set\n",
    "\n",
    "def split_data(data, test_size):\n",
    "    df = data\n",
    "    classes = df['actor_name'].unique()\n",
    "    test_names = []\n",
    "    train_names = []\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    for actor in classes:\n",
    "        actor_df = df[df['actor_name'] == actor]\n",
    "        images_number = len(actor_df)\n",
    "        train_size = math.ceil(images_number * (1 - test_size))\n",
    "        if train_size == 0:\n",
    "            train_size = 1\n",
    "        for i in range(images_number):\n",
    "            if i >= min(train_size, 9):\n",
    "                test_names.append(actor_df.iloc[i]['actor_name'])\n",
    "                test_paths.append(actor_df.iloc[i]['path'])\n",
    "                if i == 11:\n",
    "                    break\n",
    "            else:\n",
    "                train_names.append(actor_df.iloc[i]['actor_name'])\n",
    "                train_paths.append(actor_df.iloc[i]['path'])\n",
    "    train = np.vstack((train_names, train_paths))\n",
    "    test = np.vstack((test_names, test_paths))\n",
    "    train_set = pd.DataFrame(train).T\n",
    "    test_set = pd.DataFrame(test).T\n",
    "    \n",
    "    train_set.columns = ['actor_name', 'path']\n",
    "    test_set.columns = ['actor_name', 'path']\n",
    "    \n",
    "    return train_set, test_set\n",
    "            \n",
    "\n",
    "# function to remove actors that have less than 'n' images in the dataset\n",
    "\n",
    "def remove_single_occurrences(df, n):\n",
    "    count = df['actor_name'].value_counts()\n",
    "    mask = (count[df['actor_name']].values > n)\n",
    "    return df[mask]\n",
    "\n",
    "def remove_single_occurrences2(df, n):\n",
    "    count = df['actor_name'].value_counts()\n",
    "    mask = (count[df['actor_name']].values < n)\n",
    "    return df[mask]\n",
    "\n",
    "# function to load training & test sets into DataFrames\n",
    "def load_data(filename : str):\n",
    "    meta = pd.read_csv(filename).reset_index()\n",
    "    actors = meta['actor_name']\n",
    "    paths = meta['path']\n",
    "    meta = np.vstack((actors, paths))\n",
    "    meta_df = pd.DataFrame(meta).T\n",
    "    meta_df.columns = ['actor_name', 'path']\n",
    "    return meta_df\n",
    "\n",
    "#function to predict the class\n",
    "# predict a class using img file\n",
    "def predict_class(filepath):\n",
    "    import cv2\n",
    "    img = cv2.imread(filepath)\n",
    "    resized_img = cv2.resize(img, (128, 128))\n",
    "    normalizedImg = np.zeros((800, 800))\n",
    "    normalizedImg = cv2.normalize(resized_img, normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "    resized_img = normalizedImg.reshape(1, 128, 128, 3)\n",
    "    return lookup_table[str(np.argmax(model.predict(resized_img)))]\n",
    "\n",
    "def sample_till(df, maxo):\n",
    "    names = train_set['actor_name'].unique()\n",
    "    names_list = []\n",
    "    paths_list = []\n",
    "    for name in names:\n",
    "        paths = df[df['actor_name'] == name]['path']\n",
    "        for i, path in enumerate(paths):\n",
    "            if i > min(len(paths), maxo):\n",
    "                break\n",
    "            names_list.append(name)\n",
    "            paths_list.append(path)\n",
    "            \n",
    "    df_new = np.vstack((names_list, paths_list))\n",
    "    df = pd.DataFrame(df_new).T\n",
    "    df.columns = ['actor_name', 'path']\n",
    "    df = df.sample(frac = 1)\n",
    "    return df\n",
    "\n",
    "#function to save the train & test sets as well as the lookup table\n",
    "def save_info(train_gen, filename1, train_set, filename2, test_set, filename3):\n",
    "    lookup_table = dict(map(reversed, train_gen.class_indices.items()))\n",
    "    with open(filename1, 'w', encoding='utf8') as f:\n",
    "        json.dump(lookup_table, f)\n",
    "    train_set.to_csv(filename2)\n",
    "    test_set.to_csv(filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data of train & test sets that were saved from earlier training of this model\n",
    "train_set = load_data(r'data/train_set.csv')\n",
    "test_set = load_data(r'data/test_set.csv')\n",
    "lookup_table = {}\n",
    "with open('data/lookup_table.json', 'r') as f:\n",
    "    lookup_table = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ariel_Sharon         62\n",
       "Hugo_Chavez          57\n",
       "Junichiro_Koizumi    48\n",
       "Jean_Chretien        44\n",
       "Jacques_Chirac       42\n",
       "                     ..\n",
       "Leonardo_DiCaprio     7\n",
       "Jeong_Se-hyun         7\n",
       "Fernando_Gonzalez     7\n",
       "John_Abizaid          7\n",
       "Bill_Frist            7\n",
       "Name: actor_name, Length: 179, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['actor_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2734 validated image filenames belonging to 179 classes.\n",
      "Found 684 validated image filenames belonging to 179 classes.\n",
      "Number of unique classes: 179\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "#sort by actor_name and remove actors with less than 8 images\n",
    "data = new_meta\n",
    "data = remove_single_occurrences(data, 8)\n",
    "\n",
    "#Splitting into train and validation sets - can be commeneted out if loading the sets from csv\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42, stratify = data['actor_name'])\n",
    "\n",
    "#Image preprocessing\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 8\n",
    "#Normalizing the images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#Creating the generators for training and test\\validation sets\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_set,\n",
    "    x_col='path',\n",
    "    y_col='actor_name',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    test_set,\n",
    "    x_col='path',\n",
    "    y_col='actor_name',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "#Printing number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "\n",
    "#Model architecture, using l2 regularization to slow down learning curve\n",
    "model = Sequential([\n",
    "    Conv2D(8, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu', kernel_regularizer='l2'),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "#Compiling the model\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_134 (Conv2D)         (None, 126, 126, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d_134 (MaxPooli  (None, 63, 63, 8)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 61, 61, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_135 (MaxPooli  (None, 30, 30, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_136 (MaxPooli  (None, 14, 14, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 179)               23091     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 832,067\n",
      "Trainable params: 832,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "342/342 [==============================] - 29s 68ms/step - loss: 5.2581 - accuracy: 0.0227 - val_loss: 5.0705 - val_accuracy: 0.0219\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 23s 68ms/step - loss: 5.0688 - accuracy: 0.0241 - val_loss: 4.9949 - val_accuracy: 0.0380\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 22s 65ms/step - loss: 4.9496 - accuracy: 0.0384 - val_loss: 4.8489 - val_accuracy: 0.0497\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 22s 66ms/step - loss: 4.7062 - accuracy: 0.0724 - val_loss: 4.6263 - val_accuracy: 0.0599\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 22s 64ms/step - loss: 4.4010 - accuracy: 0.0947 - val_loss: 4.4020 - val_accuracy: 0.1053\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 22s 66ms/step - loss: 4.0883 - accuracy: 0.1328 - val_loss: 4.3022 - val_accuracy: 0.1155\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 23s 66ms/step - loss: 3.7898 - accuracy: 0.1778 - val_loss: 4.2690 - val_accuracy: 0.1360\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 23s 66ms/step - loss: 3.5119 - accuracy: 0.2282 - val_loss: 4.0717 - val_accuracy: 0.1535\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 23s 68ms/step - loss: 3.1948 - accuracy: 0.2897 - val_loss: 4.1252 - val_accuracy: 0.1813\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 22s 65ms/step - loss: 2.8946 - accuracy: 0.3511 - val_loss: 4.0978 - val_accuracy: 0.1930\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 23s 68ms/step - loss: 2.6734 - accuracy: 0.4049 - val_loss: 4.2614 - val_accuracy: 0.2018\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 22s 65ms/step - loss: 2.4415 - accuracy: 0.4525 - val_loss: 4.0366 - val_accuracy: 0.2061\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 2.2357 - accuracy: 0.4945 - val_loss: 4.4366 - val_accuracy: 0.2237\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 23s 68ms/step - loss: 2.0216 - accuracy: 0.5673 - val_loss: 4.4732 - val_accuracy: 0.2456\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 24s 69ms/step - loss: 1.8956 - accuracy: 0.6002 - val_loss: 4.6462 - val_accuracy: 0.2427\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 23s 66ms/step - loss: 1.7680 - accuracy: 0.6313 - val_loss: 4.9272 - val_accuracy: 0.2412\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 23s 69ms/step - loss: 1.6678 - accuracy: 0.6708 - val_loss: 5.0340 - val_accuracy: 0.2368\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 23s 67ms/step - loss: 1.5484 - accuracy: 0.7001 - val_loss: 5.0997 - val_accuracy: 0.2442\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 69ms/step - loss: 1.4745 - accuracy: 0.7323 - val_loss: 5.0883 - val_accuracy: 0.2719\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 23s 67ms/step - loss: 1.3626 - accuracy: 0.7579 - val_loss: 5.5245 - val_accuracy: 0.2617\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 23s 67ms/step - loss: 1.3868 - accuracy: 0.7440 - val_loss: 5.6267 - val_accuracy: 0.2398\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 23s 66ms/step - loss: 1.2723 - accuracy: 0.7911 - val_loss: 6.1526 - val_accuracy: 0.2792\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 23s 68ms/step - loss: 1.2247 - accuracy: 0.8050 - val_loss: 5.9771 - val_accuracy: 0.2675\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 23s 68ms/step - loss: 1.2205 - accuracy: 0.8065 - val_loss: 6.5450 - val_accuracy: 0.2734\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 23s 67ms/step - loss: 1.2102 - accuracy: 0.8189 - val_loss: 5.8648 - val_accuracy: 0.2325\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 1.1455 - accuracy: 0.8259 - val_loss: 6.4069 - val_accuracy: 0.2485\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 23s 67ms/step - loss: 1.1686 - accuracy: 0.8274 - val_loss: 6.2350 - val_accuracy: 0.2588\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 1.0581 - accuracy: 0.8493 - val_loss: 6.8907 - val_accuracy: 0.2690\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 1.0613 - accuracy: 0.8555 - val_loss: 6.9454 - val_accuracy: 0.2485\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 1.0887 - accuracy: 0.8387 - val_loss: 6.8471 - val_accuracy: 0.2427\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 1.0906 - accuracy: 0.8511 - val_loss: 6.5672 - val_accuracy: 0.2705\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9851 - accuracy: 0.8855 - val_loss: 6.6651 - val_accuracy: 0.2705\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 1.0523 - accuracy: 0.8526 - val_loss: 6.7415 - val_accuracy: 0.2792\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9693 - accuracy: 0.8837 - val_loss: 7.2719 - val_accuracy: 0.2515\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 1.0119 - accuracy: 0.8588 - val_loss: 7.3531 - val_accuracy: 0.2778\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9965 - accuracy: 0.8716 - val_loss: 7.6284 - val_accuracy: 0.2632\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.9796 - accuracy: 0.8811 - val_loss: 8.2722 - val_accuracy: 0.2383\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.9911 - accuracy: 0.8775 - val_loss: 7.1074 - val_accuracy: 0.2734\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.8960 - accuracy: 0.9001 - val_loss: 7.9189 - val_accuracy: 0.2529\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.9652 - accuracy: 0.8808 - val_loss: 7.1499 - val_accuracy: 0.2661\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.9580 - accuracy: 0.8848 - val_loss: 7.3020 - val_accuracy: 0.2675\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.9736 - accuracy: 0.8844 - val_loss: 7.3884 - val_accuracy: 0.2398\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9644 - accuracy: 0.8862 - val_loss: 7.0790 - val_accuracy: 0.2880\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.9685 - accuracy: 0.8778 - val_loss: 7.3893 - val_accuracy: 0.2807\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.8465 - accuracy: 0.9188 - val_loss: 7.9225 - val_accuracy: 0.2807\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.9460 - accuracy: 0.8848 - val_loss: 7.2649 - val_accuracy: 0.2675\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 1.0371 - accuracy: 0.8595 - val_loss: 7.0206 - val_accuracy: 0.2778\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9448 - accuracy: 0.8943 - val_loss: 7.6711 - val_accuracy: 0.2880\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.8091 - accuracy: 0.9279 - val_loss: 7.3631 - val_accuracy: 0.2865\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 24s 69ms/step - loss: 0.8381 - accuracy: 0.9155 - val_loss: 7.3135 - val_accuracy: 0.2822\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.9456 - accuracy: 0.8782 - val_loss: 7.1479 - val_accuracy: 0.2968\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.8769 - accuracy: 0.9086 - val_loss: 7.5685 - val_accuracy: 0.2851\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8724 - accuracy: 0.9078 - val_loss: 7.7401 - val_accuracy: 0.2807\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.8317 - accuracy: 0.9195 - val_loss: 7.9741 - val_accuracy: 0.2939\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9752 - accuracy: 0.8775 - val_loss: 7.7691 - val_accuracy: 0.2822\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8926 - accuracy: 0.9023 - val_loss: 7.3536 - val_accuracy: 0.2792\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8617 - accuracy: 0.9140 - val_loss: 7.3880 - val_accuracy: 0.2880\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.8334 - accuracy: 0.9137 - val_loss: 7.1591 - val_accuracy: 0.2749\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.9297 - accuracy: 0.8877 - val_loss: 7.4961 - val_accuracy: 0.2822\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8595 - accuracy: 0.9144 - val_loss: 7.3201 - val_accuracy: 0.2719\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8415 - accuracy: 0.9177 - val_loss: 7.1416 - val_accuracy: 0.3070\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.7920 - accuracy: 0.9239 - val_loss: 7.4922 - val_accuracy: 0.2851\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.8887 - accuracy: 0.9005 - val_loss: 7.0048 - val_accuracy: 0.2968\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 70ms/step - loss: 0.8836 - accuracy: 0.9053 - val_loss: 7.2013 - val_accuracy: 0.3056\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7423 - accuracy: 0.9396 - val_loss: 7.4671 - val_accuracy: 0.3070\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8771 - accuracy: 0.9001 - val_loss: 7.1860 - val_accuracy: 0.2982\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8268 - accuracy: 0.9155 - val_loss: 7.3589 - val_accuracy: 0.2953\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.9023 - accuracy: 0.8943 - val_loss: 7.4524 - val_accuracy: 0.2924\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.8008 - accuracy: 0.9272 - val_loss: 7.3578 - val_accuracy: 0.2997\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.7550 - accuracy: 0.9393 - val_loss: 7.2576 - val_accuracy: 0.2997\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8621 - accuracy: 0.8994 - val_loss: 7.1694 - val_accuracy: 0.2982\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8667 - accuracy: 0.9031 - val_loss: 6.6916 - val_accuracy: 0.2865\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7563 - accuracy: 0.9367 - val_loss: 7.1925 - val_accuracy: 0.3041\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7515 - accuracy: 0.9382 - val_loss: 7.2234 - val_accuracy: 0.2851\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8028 - accuracy: 0.9199 - val_loss: 7.6420 - val_accuracy: 0.2822\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.8754 - accuracy: 0.8906 - val_loss: 6.8358 - val_accuracy: 0.3202\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7864 - accuracy: 0.9290 - val_loss: 7.2427 - val_accuracy: 0.2909\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.8143 - accuracy: 0.9210 - val_loss: 6.8797 - val_accuracy: 0.2953\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 69ms/step - loss: 0.7268 - accuracy: 0.9415 - val_loss: 7.4203 - val_accuracy: 0.3173\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7623 - accuracy: 0.9265 - val_loss: 7.1801 - val_accuracy: 0.3041\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8155 - accuracy: 0.9100 - val_loss: 7.5772 - val_accuracy: 0.3099\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.8024 - accuracy: 0.9173 - val_loss: 7.4736 - val_accuracy: 0.2690\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8853 - accuracy: 0.8983 - val_loss: 6.8891 - val_accuracy: 0.3070\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7394 - accuracy: 0.9415 - val_loss: 7.2523 - val_accuracy: 0.2792\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.6990 - accuracy: 0.9448 - val_loss: 7.0165 - val_accuracy: 0.3085\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7619 - accuracy: 0.9228 - val_loss: 7.4007 - val_accuracy: 0.2778\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8601 - accuracy: 0.9027 - val_loss: 6.9097 - val_accuracy: 0.3114\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.7824 - accuracy: 0.9272 - val_loss: 7.1905 - val_accuracy: 0.3041\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7405 - accuracy: 0.9448 - val_loss: 6.6988 - val_accuracy: 0.3304\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.6895 - accuracy: 0.9488 - val_loss: 6.8261 - val_accuracy: 0.3392\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7219 - accuracy: 0.9309 - val_loss: 7.0696 - val_accuracy: 0.3216\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.8581 - accuracy: 0.8987 - val_loss: 6.6817 - val_accuracy: 0.3026\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.8494 - accuracy: 0.9053 - val_loss: 6.5616 - val_accuracy: 0.3319\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.6583 - accuracy: 0.9689 - val_loss: 6.8290 - val_accuracy: 0.3129\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.6684 - accuracy: 0.9510 - val_loss: 6.9980 - val_accuracy: 0.3041\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.8232 - accuracy: 0.9075 - val_loss: 6.8808 - val_accuracy: 0.3085\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7179 - accuracy: 0.9400 - val_loss: 7.2774 - val_accuracy: 0.3026\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 26s 76ms/step - loss: 0.7509 - accuracy: 0.9247 - val_loss: 7.3497 - val_accuracy: 0.2836\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.7714 - accuracy: 0.9199 - val_loss: 6.8426 - val_accuracy: 0.3099\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.7518 - accuracy: 0.9360 - val_loss: 6.8538 - val_accuracy: 0.3246\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6729 - accuracy: 0.9495 - val_loss: 7.3218 - val_accuracy: 0.3026\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6707 - accuracy: 0.9499 - val_loss: 6.9762 - val_accuracy: 0.3085\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.7662 - accuracy: 0.9195 - val_loss: 6.7966 - val_accuracy: 0.2953\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7916 - accuracy: 0.9162 - val_loss: 6.6342 - val_accuracy: 0.3129\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 26s 76ms/step - loss: 0.7632 - accuracy: 0.9276 - val_loss: 6.5616 - val_accuracy: 0.3275\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6798 - accuracy: 0.9440 - val_loss: 7.0449 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.6807 - accuracy: 0.9422 - val_loss: 7.3989 - val_accuracy: 0.2982\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.7129 - accuracy: 0.9316 - val_loss: 7.2958 - val_accuracy: 0.3202\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.7346 - accuracy: 0.9276 - val_loss: 7.3727 - val_accuracy: 0.3012\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7716 - accuracy: 0.9166 - val_loss: 6.9299 - val_accuracy: 0.3289\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.6525 - accuracy: 0.9561 - val_loss: 6.5732 - val_accuracy: 0.3260\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7530 - accuracy: 0.9294 - val_loss: 6.8094 - val_accuracy: 0.3377\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.7716 - accuracy: 0.9261 - val_loss: 6.6868 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7127 - accuracy: 0.9327 - val_loss: 7.4205 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7167 - accuracy: 0.9367 - val_loss: 6.7097 - val_accuracy: 0.3246\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 24s 72ms/step - loss: 0.6836 - accuracy: 0.9466 - val_loss: 6.4863 - val_accuracy: 0.3260\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6593 - accuracy: 0.9481 - val_loss: 6.9703 - val_accuracy: 0.3129\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.6532 - accuracy: 0.9492 - val_loss: 6.7185 - val_accuracy: 0.3348\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7332 - accuracy: 0.9312 - val_loss: 6.8624 - val_accuracy: 0.3289\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.6753 - accuracy: 0.9470 - val_loss: 6.8960 - val_accuracy: 0.3099\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.6925 - accuracy: 0.9415 - val_loss: 7.2014 - val_accuracy: 0.3085\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 72ms/step - loss: 0.7590 - accuracy: 0.9225 - val_loss: 7.3231 - val_accuracy: 0.2968\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.7986 - accuracy: 0.9188 - val_loss: 7.0227 - val_accuracy: 0.3363\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6898 - accuracy: 0.9535 - val_loss: 6.7350 - val_accuracy: 0.3319\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6440 - accuracy: 0.9572 - val_loss: 6.9066 - val_accuracy: 0.3567\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.5933 - accuracy: 0.9685 - val_loss: 6.8142 - val_accuracy: 0.3406\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 24s 71ms/step - loss: 0.6626 - accuracy: 0.9422 - val_loss: 6.1996 - val_accuracy: 0.3260\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.8055 - accuracy: 0.9078 - val_loss: 6.9007 - val_accuracy: 0.3129\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.7694 - accuracy: 0.9254 - val_loss: 6.4028 - val_accuracy: 0.3582\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.6735 - accuracy: 0.9510 - val_loss: 6.6800 - val_accuracy: 0.3406\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.6374 - accuracy: 0.9565 - val_loss: 7.1715 - val_accuracy: 0.3114\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.6410 - accuracy: 0.9550 - val_loss: 6.9660 - val_accuracy: 0.3099\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.7500 - accuracy: 0.9195 - val_loss: 6.3325 - val_accuracy: 0.3406\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 26s 75ms/step - loss: 0.6610 - accuracy: 0.9510 - val_loss: 6.4172 - val_accuracy: 0.3260\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 25s 74ms/step - loss: 0.7112 - accuracy: 0.9356 - val_loss: 7.0187 - val_accuracy: 0.3611\n",
      "Epoch 1/5\n",
      "342/342 [==============================] - 26s 77ms/step - loss: 0.6685 - accuracy: 0.9451 - val_loss: 6.6623 - val_accuracy: 0.3231\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 25s 73ms/step - loss: 0.6233 - accuracy: 0.9554 - val_loss: 6.5974 - val_accuracy: 0.3421\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 26s 77ms/step - loss: 0.6522 - accuracy: 0.9444 - val_loss: 7.1481 - val_accuracy: 0.3246\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 24s 69ms/step - loss: 0.6622 - accuracy: 0.9378 - val_loss: 6.3138 - val_accuracy: 0.3582\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 12s 34ms/step - loss: 0.7337 - accuracy: 0.9257 - val_loss: 6.5299 - val_accuracy: 0.3216\n",
      "Epoch 1/5\n",
      " 56/342 [===>..........................] - ETA: 8s - loss: 0.6697 - accuracy: 0.9552"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [265], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m80\u001b[39m):        \n\u001b[1;32m----> 7\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      8\u001b[0m         train_generator,\n\u001b[0;32m      9\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_generator),\n\u001b[0;32m     10\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(epochs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m80\u001b[39m),\n\u001b[0;32m     11\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[0;32m     12\u001b[0m         validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_generator))\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m## save stuff after 5 epochs\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     hist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# since we've experienced crashes during the training, \n",
    "#we made the training in a for loop where every 5 epochs we save the model and output the log into a csv file\n",
    "\n",
    "epochs = 400\n",
    "for i in range(0,80):        \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=int(epochs/80),\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator))\n",
    "    \n",
    "    ## save stuff after 5 epochs\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    hist_csv_file = str(batch_size) + '_history_' + str((i+1) * 5) + \".csv\"\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    model.save(str(batch_size) + '_epoch' + str(i+1 * 5) + '.h5')\n",
    "\n",
    "# Save the trained model\n",
    "model.save(str(batch_size) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info(train_generator, \"lookup_table.json\", train_set, \"train_set.csv\", test_set, \"test_set.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
